{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Housing Prices- Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main aim of this project is to predict the house price based on various features \n",
    "\n",
    "#### Dataset to downloaded from the below link\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be performing all the below steps in Feature Engineering\n",
    "\n",
    "1. Missing values\n",
    "2. Temporal variables\n",
    "3. Categorical variables: remove rare labels\n",
    "4. Standarise the values of the variables to the same range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('train.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Always remember there way always be a chance of data leakage so we need to split the data first and then apply feature\n",
    "## Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(dataset,dataset['SalePrice'],test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us capture all the nan values\n",
    "## First lets handle Categorical features which are missing\n",
    "features_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes=='O']\n",
    "\n",
    "for feature in features_nan:\n",
    "    print(\"{}: {}% missing values\".format(feature,np.round(dataset[feature].isnull().mean(),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace missing value with a new label\n",
    "def replace_cat_feature(dataset,features_nan):\n",
    "    data=dataset.copy()\n",
    "    data[features_nan]=data[features_nan].fillna('Missing')\n",
    "    return data\n",
    "\n",
    "dataset=replace_cat_feature(dataset,features_nan)\n",
    "\n",
    "dataset[features_nan].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now lets check for numerical variables the contains missing values\n",
    "numerical_with_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes!='O']\n",
    "\n",
    "## We will print the numerical nan variables and percentage of missing values\n",
    "\n",
    "for feature in numerical_with_nan:\n",
    "    print(\"{}: {}% missing value\".format(feature,np.around(dataset[feature].isnull().mean(),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replacing the numerical Missing Values\n",
    "\n",
    "for feature in numerical_with_nan:\n",
    "    ## We will replace by using median since there are outliers\n",
    "    median_value=dataset[feature].median()\n",
    "    \n",
    "    ## create a new feature to capture nan values\n",
    "    dataset[feature+'nan']=np.where(dataset[feature].isnull(),1,0)\n",
    "    dataset[feature].fillna(median_value,inplace=True)\n",
    "    \n",
    "dataset[numerical_with_nan].isnull().sum()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Temporal Variables (Date Time Variables)\n",
    "\n",
    "for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n",
    "       \n",
    "    dataset[feature]=dataset['YrSold']-dataset[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Variables\n",
    "Since the numerical variables are skewed we will perform log normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n",
    "\n",
    "for feature in num_features:\n",
    "    dataset[feature]=np.log(dataset[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Rare Categorical Feature\n",
    "\n",
    "We will remove categorical variables that are present less than 1% of the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[feature for feature in dataset.columns if dataset[feature].dtype=='O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in categorical_features:\n",
    "    temp=dataset.groupby(feature)['SalePrice'].count()/len(dataset)\n",
    "    temp_df=temp[temp>0.01].index\n",
    "    dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],'Rare_var')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in categorical_features:\n",
    "    labels_ordered=dataset.groupby([feature])['SalePrice'].mean().sort_values().index\n",
    "    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n",
    "    dataset[feature]=dataset[feature].map(labels_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_feature=[feature for feature in dataset.columns if feature not in ['Id','SalePerice'] ]\n",
    "len(scaling_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scale=[feature for feature in dataset.columns if feature not in ['Id','SalePrice']]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(dataset[feature_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform(dataset[feature_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the train and test set, and add on the Id and SalePrice variables\n",
    "data = pd.concat([dataset[['Id', 'SalePrice']].reset_index(drop=True),\n",
    "                    pd.DataFrame(scaler.transform(dataset[feature_scale]), columns=feature_scale)],\n",
    "                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('X_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
